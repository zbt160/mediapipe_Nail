{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5909ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mediapipeNew.python.solutions import hands,drawing_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3f74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediapipeNew\\modules\\hand_landmark\\hand_landmark_tracking_cpu.pbtxt\n",
      "Printing HERE <<<<<<\n",
      "ROOT PAth: D:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\n",
      "Complete_path:  D:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\\mediapipeNew\\modules\\hand_landmark\\hand_landmark_tracking_cpu.pbtxt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to parse the binary graph: D:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\\mediapipeNew\\modules\\hand_landmark\\hand_landmark_tracking_cpu.pbtxt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m mpHands \u001b[38;5;241m=\u001b[39m hands\n\u001b[1;32m----> 2\u001b[0m hands \u001b[38;5;241m=\u001b[39m \u001b[43mmpHands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_num_hands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m mpDraw \u001b[38;5;241m=\u001b[39m drawing_utils\n",
      "File \u001b[1;32mD:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\\mediapipeNew\\python\\solutions\\hands.py:117\u001b[0m, in \u001b[0;36mHands.__init__\u001b[1;34m(self, static_image_mode, max_num_hands, model_complexity, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m              static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     94\u001b[0m              max_num_hands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     95\u001b[0m              model_complexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     96\u001b[0m              min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     97\u001b[0m              min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;124;03m\"\"\"Initializes a MediaPipe Hand object.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m      https://solutions.mediapipe.dev/hands#min_tracking_confidence.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_BINARYPB_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m      \u001b[49m\u001b[43mside_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_complexity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_complexity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_hands\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_hands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_prev_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcalculator_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpalmdetectioncpu__TensorsToDetectionsCalculator.min_score_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhandlandmarkcpu__ThresholdingCalculator.threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_hand_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_hand_world_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_handedness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    133\u001b[0m \u001b[43m      \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\\mediapipeNew\\python\\solution_base.py:274\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    272\u001b[0m validated_graph \u001b[38;5;241m=\u001b[39m validated_graph_config\u001b[38;5;241m.\u001b[39mValidatedGraphConfig()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_graph_path:\n\u001b[1;32m--> 274\u001b[0m   \u001b[43mvalidated_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m   validated_graph\u001b[38;5;241m.\u001b[39minitialize(graph_config\u001b[38;5;241m=\u001b[39mgraph_config)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to parse the binary graph: D:\\FreeLancing\\Projects\\Nails_Segmentation\\mediapipe_Nail\\mediapipeNew\\modules\\hand_landmark\\hand_landmark_tracking_cpu.pbtxt"
     ]
    }
   ],
   "source": [
    "mpHands = hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7bcee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE HAND_PROCESS\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    x, y, c = frame.shape\n",
    "\n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get hand landmark prediction\n",
    "    result = hands.process(framergb)\n",
    "\n",
    "#     print(result.detection)\n",
    "    break\n",
    "cap.release()\n",
    "    \n",
    "#     className = ''\n",
    "\n",
    "#     # post process the result\n",
    "#     if result.multi_hand_landmarks:\n",
    "#         landmarks = []\n",
    "#         for handslms in result.multi_hand_landmarks:\n",
    "#             for lm in handslms.landmark:\n",
    "#                 # print(id, lm)\n",
    "#                 lmx = int(lm.x * x)\n",
    "#                 lmy = int(lm.y * y)\n",
    "\n",
    "#                 landmarks.append([lmx, lmy])\n",
    "\n",
    "#             # Drawing landmarks on frames\n",
    "#             mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "#             # Predict gesture\n",
    "# #             prediction = model.predict([landmarks])\n",
    "# #             # print(prediction)\n",
    "# #             classID = np.argmax(prediction)\n",
    "# #             className = classNames[classID]\n",
    "\n",
    "#     # show the prediction on the frame\n",
    "# #     cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "# #                    1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "#     # Show the final qoutput\n",
    "#     cv2.imshow(\"Output\", frame) \n",
    "\n",
    "#     if cv2.waitKey(1) == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # release the webcam and destroy all active windows\n",
    "# cap.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1ee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5a8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solution_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64d868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
